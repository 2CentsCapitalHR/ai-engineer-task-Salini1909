# -*- coding: utf-8 -*-
"""Task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1733NNFbGxwHx_4EO9i-0rh-k0Wpp5E2H
"""

# Run this cell first
!pip install -q python-docx requests

from getpass import getpass
import os

HF_TOKEN = getpass("Paste your Hugging Face API token (keeps it hidden): ")
if not HF_TOKEN:
    raise SystemExit("No token provided â€” stop and paste your Hugging Face token.")
os.environ['HF_TOKEN'] = HF_TOKEN
print("Token stored in runtime (not saved in notebook).")

from google.colab import files
uploaded = files.upload()  # choose your .docx file when the file picker appears

# pick the first uploaded file
docx_filename = list(uploaded.keys())[0]
print("Uploaded file:", docx_filename)



API_URL = "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta"

headers = {"Authorization": f"Bearer {HF_API_KEY}"}

payload = {
    "inputs": prompt,
    "parameters": {"max_new_tokens": 500}
}

response = requests.post(API_URL, headers=headers, json=payload)

if response.status_code != 200:
    print(f"Error {response.status_code}: {response.text}")
else:
    result = response.json()
    print("=== Review Result ===")
    print(result[0]["generated_text"])



!pip install python-docx gradio

import gradio as gr
import json
import os
from docx import Document

# ADGM required checklist
required_docs = [
    "Articles of Association",
    "Memorandum of Association",
    "UBO Declaration Form",
    "Register of Members and Directors",
    "Incorporation Application Form"
]

def process_docs(files):
    uploaded_doc_names = []
    issues_found = []

    for file in files:
        filename = os.path.basename(file.name)
        uploaded_doc_names.append(filename.replace(".docx", "").strip())

        # Read DOCX content
        doc = Document(file.name)
        full_text = "\n".join([para.text for para in doc.paragraphs])

        # Dummy example check â€” flag jurisdiction issue if "ADGM" not found
        if "ADGM" not in full_text:
            issues_found.append({
                "document": filename.replace(".docx", ""),
                "section": "Clause 3.1",
                "issue": "Jurisdiction clause does not specify ADGM",
                "severity": "High",
                "suggestion": "Update jurisdiction to ADGM Courts."
            })

    # Identify missing documents
    missing_docs = [d for d in required_docs if d not in uploaded_doc_names]

    # Prepare final JSON output
    result = {
        "process": "Company Incorporation",
        "documents_uploaded": len(uploaded_doc_names),
        "required_documents": len(required_docs),
        "missing_document": ", ".join(missing_docs) if missing_docs else None,
        "issues_found": issues_found
    }

    return json.dumps(result, indent=4)

iface = gr.Interface(
    fn=process_docs,
    inputs=gr.Files(file_types=[".docx"], label="Upload one or more .docx files"),
    outputs="text",
    title="ADGM Document Compliance Checker",
    description="Upload one or more .docx files to check compliance and generate JSON output."
)

iface.launch(share=True)



import gradio as gr
import json
import os
from docx import Document
import PyPDF2

def extract_adgm_references(pdf_file):
    """Extracts document names and links from PDF"""
    with open(pdf_file.name, "rb") as f:
        reader = PyPDF2.PdfReader(f)
        text = "\n".join(page.extract_text() for page in reader.pages if page.extract_text())
    refs = {}
    lines = text.split("\n")
    for i in range(len(lines)-1):
        if lines[i].strip() and lines[i+1].startswith("http"):
            refs[lines[i].strip()] = lines[i+1].strip()
    return refs

def process_with_pdf(pdf_file, docx_files):
    # Extract required docs from PDF
    adgm_refs = extract_adgm_references(pdf_file)
    required_docs = list(adgm_refs.keys())

    uploaded_doc_names = []
    issues_found = []

    for file in docx_files:
        filename = os.path.basename(file.name)
        name_without_ext = filename.replace(".docx", "").strip()
        uploaded_doc_names.append(name_without_ext)

        # Read DOCX text
        doc = Document(file.name)
        full_text = "\n".join([para.text for para in doc.paragraphs])

        # Example issue: flag if "ADGM" not mentioned
        if "ADGM" not in full_text:
            issues_found.append({
                "document": name_without_ext,
                "section": "Clause 3.1",
                "issue": "Jurisdiction clause does not specify ADGM",
                "severity": "High",
                "suggestion": "Update jurisdiction to ADGM Courts."
            })

    # Find missing docs
    missing_docs = [d for d in required_docs if d not in uploaded_doc_names]

    # Build JSON output
    result = {
        "process": "Company Incorporation",
        "documents_uploaded": len(uploaded_doc_names),
        "required_documents": len(required_docs),
        "missing_document": ", ".join(missing_docs) if missing_docs else None,
        "issues_found": issues_found
    }

    return json.dumps(result, indent=4)

with gr.Blocks() as demo:
    gr.Markdown("## ðŸ“‘ ADGM Document Compliance Checker (PDF + DOCX)")

    pdf_input = gr.File(label="Upload ADGM References PDF", file_types=[".pdf"])
    docx_input = gr.Files(label="Upload one or more .docx files", file_types=[".docx"])
    output_box = gr.Textbox(label="JSON Output", lines=15)

    run_btn = gr.Button("Run Compliance Check")
    run_btn.click(fn=process_with_pdf, inputs=[pdf_input, docx_input], outputs=output_box)

demo.launch(share=True)

